{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraires","metadata":{}},{"cell_type":"code","source":"! pip install neurokit","metadata":{"execution":{"iopub.status.busy":"2022-02-25T21:04:10.279327Z","iopub.execute_input":"2022-02-25T21:04:10.27966Z","iopub.status.idle":"2022-02-25T21:04:25.325667Z","shell.execute_reply.started":"2022-02-25T21:04:10.279576Z","shell.execute_reply":"2022-02-25T21:04:25.324954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install -q -U tensorflow-addons","metadata":{"execution":{"iopub.status.busy":"2022-02-26T19:37:07.756105Z","iopub.execute_input":"2022-02-26T19:37:07.756471Z","iopub.status.idle":"2022-02-26T19:37:22.100906Z","shell.execute_reply.started":"2022-02-26T19:37:07.756366Z","shell.execute_reply":"2022-02-26T19:37:22.100021Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"####### Importing Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport os \nimport math\nimport seaborn as sns\nimport pickle\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.utils import shuffle\nimport tensorflow_addons as tfa\nimport gc","metadata":{"execution":{"iopub.status.busy":"2022-02-26T19:37:22.105352Z","iopub.execute_input":"2022-02-26T19:37:22.105633Z","iopub.status.idle":"2022-02-26T19:37:27.492279Z","shell.execute_reply.started":"2022-02-26T19:37:22.105591Z","shell.execute_reply":"2022-02-26T19:37:27.491553Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nexcept ValueError:\n    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"###### Dowloading Data\n#! wget https://uni-siegen.sciebo.de/s/HGdUkoNlW1Ub0Gx/download\n#! unzip './download'\n# Clone the git repo\n! git clone --quiet https://github.com/FedotovD/WESAD_ECG_SSL.git","metadata":{"execution":{"iopub.status.busy":"2022-02-26T19:37:33.833181Z","iopub.execute_input":"2022-02-26T19:37:33.833464Z","iopub.status.idle":"2022-02-26T19:38:08.704156Z","shell.execute_reply.started":"2022-02-26T19:37:33.833432Z","shell.execute_reply":"2022-02-26T19:38:08.703205Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"###### Data Reading\ndef read_data(participants):\n    # This function reads the data according to participants list taken as an argument\n\n    X = []\n\n    for filename in train_participants:\n        temp = pd.read_csv('WESAD_ECG_SSL/data/{}.csv'.format(filename), index_col=0)\n        X.append(temp)\n    \n    X = pd.concat(X, axis=0)\n    y = X.lab.to_numpy()\n    y = class_to_number(y)\n    X = X.iloc[:,2:].to_numpy()\n    \n    return X, y\n\ndef class_to_number(labels):\n    # This function converts classes from categories to numbers, e.g. \"Base\" to 0, \"Fun\" to 1, etc.\n\n    classes = np.unique(labels)\n\n    for c in range(len(classes)):\n        labels[labels == classes[c]] = c\n    \n    return np.array(labels, dtype=int)\n\ndef one_hot_encoding(labels, num_classes):\n    # This function performs one hot encoding for labels\n\n    if type(labels[0]) == str:\n        labels = class_to_number(labels)\n\n    elif type(labels[0]) == float:\n        labels = int(labels)\n\n    Y = np.eye(num_classes)[labels]\n\n    return Y\n\n# Define train and test sets\ntrain_participants = ['S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10']\ndevel_participants = ['S11', 'S13', 'S14']\ntest_participants  = ['S15', 'S16', 'S17']\n\n\n# Read files for train and test participants\nX_train, y_train = read_data(train_participants)\nX_devel, y_devel = read_data(devel_participants)\nX_test, y_test = read_data(test_participants)\n\n# Normalize data\nscaler = StandardScaler()\nX_train_norm = scaler.fit_transform(X_train)\nX_devel_norm = scaler.transform(X_devel)\nX_test_norm  = scaler.transform(X_test)\n\n# Convert labels to one-hot\ny_train_onehot = one_hot_encoding(y_train, 3)\ny_devel_onehot = one_hot_encoding(y_devel, 3)\ny_test_onehot = one_hot_encoding(y_test, 3)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T19:38:55.160947Z","iopub.execute_input":"2022-02-26T19:38:55.161235Z","iopub.status.idle":"2022-02-26T19:39:01.778089Z","shell.execute_reply.started":"2022-02-26T19:38:55.161206Z","shell.execute_reply":"2022-02-26T19:39:01.777361Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"###### Saving Numpy Arrays\nnp.savez_compressed('X_train_MHM_Stress.npz',np.array(X_train_norm))\nnp.savez_compressed('y_train_MHM_Stress.npz',np.array(y_train))\nnp.savez_compressed('X_dev_MHM_Stress.npz',np.array(X_test_norm))\nnp.savez_compressed('y_dev_MHM_Stress.npz',np.array(y_test)) ","metadata":{"execution":{"iopub.status.busy":"2022-02-26T19:39:06.431251Z","iopub.execute_input":"2022-02-26T19:39:06.431544Z","iopub.status.idle":"2022-02-26T19:39:10.304964Z","shell.execute_reply.started":"2022-02-26T19:39:06.431513Z","shell.execute_reply":"2022-02-26T19:39:10.304209Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"###### Loading Dataset\nX_train = np.array(np.load('./X_train_MHM_Stress.npz',allow_pickle=True)['arr_0'],dtype=np.float16)\nX_train = np.reshape(X_train,(2019,2560,1))\nX_dev = np.array(np.load('./X_dev_MHM_Stress.npz',allow_pickle=True)['arr_0'],dtype=np.float16)\nX_dev = np.reshape(X_dev,(2019,2560,1))\ny_train = np.load('./y_train_MHM_Stress.npz',allow_pickle=True)['arr_0']\ny_dev = np.load('./y_dev_MHM_Stress.npz',allow_pickle=True)['arr_0']\n\n###### Shuffling Numpy Arrays\nX_train,y_train = shuffle(X_train,y_train)\nX_dev,y_dev = shuffle(X_dev,y_dev)\n\nprint(X_train.shape)\nprint(X_dev.shape)\nprint(y_train.shape)\nprint(y_dev.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T19:39:10.306505Z","iopub.execute_input":"2022-02-26T19:39:10.306770Z","iopub.status.idle":"2022-02-26T19:39:10.953108Z","shell.execute_reply.started":"2022-02-26T19:39:10.306729Z","shell.execute_reply":"2022-02-26T19:39:10.952383Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"###### Signal Fourier Analysis\n\n##### Function to Plot Frequency of Signal\ndef plot_fourier_spectrum(signal):\n    \n    \"\"\"\n    Funtion to plot Fourier Spectrum of any Bioradar Signal\n    \n    INPUTS:-\n    1)signal : Normalized Signal in time domain\n    \n    \"\"\"\n    N = 200 # Signal Duration (Sampling Frequency)\n    \n    yf = fft(signal)\n    xf = fftfreq(N, 1/100)\n    \n    plt.plot(sorted(xf), np.abs(yf))\n    plt.grid('True')\n    #plt.show()\n\n##### Function to Plot Signal in Temporal Domain\ndef plot_time(signal):\n    \n    \"\"\"\n    Funtion to  Signal in Temporal Domain\n    \n    INPUTS:-\n    1)signal : Normalized Signal in time domain\n    \n    \"\"\"\n    plt.plot(np.arange(2560),signal)\n    plt.grid('True')\n    \n##### Fourier Spectrum Plotting\nX_NRR = []\nX_ARR = []\n\nfor i in range(200):\n    if(y_train[i]==1):\n        X_NRR.append(X_train[i])\n    else:\n        X_ARR.append(X_train[i])\n        \nfor i in range(20):\n    print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n    print('-----------------------------------------------------')\n    print('Fourier')\n    #plot_fourier_spectrum(X_NRR[i])\n    #plot_fourier_spectrum(X_ARR[i])\n    plt.show()\n    print('-----------------------------------------------------')\n    print('Time')\n    plot_time(X_NRR[i])\n    #plot_time(X_ARR[i])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T21:50:28.28283Z","iopub.execute_input":"2022-02-25T21:50:28.283385Z","iopub.status.idle":"2022-02-25T21:50:31.534236Z","shell.execute_reply.started":"2022-02-25T21:50:28.283347Z","shell.execute_reply":"2022-02-25T21:50:31.533557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Making","metadata":{}},{"cell_type":"markdown","source":"## Transformer","metadata":{}},{"cell_type":"code","source":"def get_angles(pos, i, d_model):\n    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n    return pos * angle_rates\n\ndef positional_encoding(position, d_model):\n    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n                          np.arange(d_model)[np.newaxis, :],\n                          d_model)\n  \n  # apply sin to even indices in the array; 2i\n    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n  \n  # apply cos to odd indices in the array; 2i+1\n    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n    \n    pos_encoding = angle_rads[np.newaxis, ...]\n    \n    return tf.cast(pos_encoding, dtype=tf.float32)\n\ndef create_padding_mask(seq):\n    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n  \n    # add extra dimensions to add the padding\n    # to the attention logits. \n    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n\ndef scaled_dot_product_attention(q, k, v, mask):\n    \"\"\"Calculate the attention weights.\n    q, k, v must have matching leading dimensions.\n    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n    The mask has different shapes depending on its type(padding or look ahead) \n    but it must be broadcastable for addition.\n\n    Args:\n    q: query shape == (..., seq_len_q, depth)\n    k: key shape == (..., seq_len_k, depth)\n    v: value shape == (..., seq_len_v, depth_v)\n    mask: Float tensor with shape broadcastable \n          to (..., seq_len_q, seq_len_k). Defaults to None.\n\n    Returns:\n    output, attention_weights\n    \"\"\"\n\n    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n  \n    # scale matmul_qk\n    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n\n    # add the mask to the scaled tensor.\n    if mask is not None:\n        scaled_attention_logits += (mask * -1e9)  \n\n    # softmax is normalized on the last axis (seq_len_k) so that the scores\n    # add up to 1.\n    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n\n    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n\n    return output, attention_weights\n\nclass MultiHeadAttention(tf.keras.layers.Layer):\n    \n    def __init__(self, d_model, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        self.num_heads = num_heads\n        self.d_model = d_model\n\n        assert d_model % self.num_heads == 0\n\n        self.depth = d_model // self.num_heads\n\n        self.wq = tf.keras.layers.Dense(d_model)\n        self.wk = tf.keras.layers.Dense(d_model)\n        self.wv = tf.keras.layers.Dense(d_model)\n\n        self.dense = tf.keras.layers.Dense(d_model)\n\n    def get_config(self):\n        config = super(MultiHeadAttention, self).get_config().copy()\n        config.update({\n            'd_model': self.d_model,\n            'num_heads':self.num_heads\n        })\n        \n    def split_heads(self, x, batch_size):\n        \n        \"\"\"Split the last dimension into (num_heads, depth).\n        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n        \"\"\"\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n        return tf.transpose(x, perm=[0, 2, 1, 3])\n    \n    def call(self, v, k, q, mask):\n        batch_size = tf.shape(q)[0]\n\n        q = self.wq(q)  # (batch_size, seq_len, d_model)\n        k = self.wk(k)  # (batch_size, seq_len, d_model)\n        v = self.wv(v)  # (batch_size, seq_len, d_model)\n\n        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n\n        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n        scaled_attention, attention_weights = scaled_dot_product_attention(\n            q, k, v, mask)\n\n        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n\n        concat_attention = tf.reshape(scaled_attention, \n                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n\n        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n\n        return output, attention_weights\n\ndef point_wise_feed_forward_network(d_model, dff):\n    return tf.keras.Sequential([\n      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n  ])\n\nclass Encoder(tf.keras.layers.Layer):\n    def __init__(self, num_layers, d_model, num_heads, dff,\n               maximum_position_encoding, rate=0.1):\n        super(Encoder, self).__init__()\n\n        self.d_model = d_model\n        self.num_layers = num_layers\n        self.num_heads = num_heads\n        self.dff = dff\n        self.maximum_position_encoding = maximum_position_encoding\n        self.rate = rate\n\n        #self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n        self.pos_encoding = positional_encoding(maximum_position_encoding, \n                                                self.d_model)\n\n\n        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n                           for _ in range(num_layers)]\n\n        self.dropout = tf.keras.layers.Dropout(rate)\n        \n    def get_config(self):\n        config = super(Encoder, self).get_config().copy()\n        config.update({\n            'num_layers': self.num_layers,\n            'd_model': self.d_model,\n            'num_heads':self.num_heads,\n            'dff':self.dff,\n            'maximum_position_encoding':self.maximum_position_encoding,\n            'rate':self.rate  \n        })\n        \n    def call(self, x, training, mask):\n\n        seq_len = tf.shape(x)[1]\n\n        # adding embedding and position encoding.\n        #x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n        x += self.pos_encoding[:, :seq_len, :]\n\n        x = self.dropout(x, training=training)         \n\n        for i in range(self.num_layers):\n            x = self.enc_layers[i](x, training, mask)\n\n        return x  # (batch_size, input_seq_len, d_model)\n\nclass EncoderLayer(tf.keras.layers.Layer):\n    def __init__(self, d_model, num_heads, dff, rate=0.1):\n        super(EncoderLayer, self).__init__()\n        \n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.dff = dff\n        self.rate = rate\n\n        self.mha = MultiHeadAttention(d_model, num_heads)\n        self.ffn = point_wise_feed_forward_network(d_model, dff)\n\n        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n        self.dropout1 = tf.keras.layers.Dropout(rate)\n        self.dropout2 = tf.keras.layers.Dropout(rate)\n        \n    def get_config(self):\n        config = super(EncoderLayer, self).get_config().copy()\n        config.update({\n            'd_model': self.d_model,\n            'num_heads':self.num_heads,\n            'dff':self.dff,\n            'rate':self.rate  \n        })\n        \n    def call(self, x, training, mask):\n\n        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n \n        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n    \n        return out2\n    \nclass Transformer(tf.keras.Model):\n    def __init__(self, num_layers, d_model, num_heads, dff, \n                 pe_input, rate=0.1):\n        super(Transformer, self).__init__()\n        \n        self.num_layers = num_layers\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.dff = dff\n        self.pe_input = pe_input\n        self.rate = rate\n        \n        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n                                pe_input, rate)\n        \n    def get_config(self):\n        config = super(Transformer,self).get_config().copy()\n        config.update({\n            'num_layers': self.num_layers,\n            'd_model': self.d_model,\n            'num_heads':self.num_heads,\n            'dff':self.dff,\n            'pe_input':self.pe_input,\n            'rate':self.rate  \n        })\n    \n    def call(self, inp, training, enc_padding_mask):\n        return self.encoder(inp, training, enc_padding_mask)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T19:43:52.004966Z","iopub.execute_input":"2022-02-26T19:43:52.005291Z","iopub.status.idle":"2022-02-26T19:43:52.044364Z","shell.execute_reply.started":"2022-02-26T19:43:52.005258Z","shell.execute_reply":"2022-02-26T19:43:52.043495Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"###### Defining Architecture\n\n#with tpu_strategy.scope():\n\n#### Defining Hyperparameters\nnum_layers = 2\nd_model = 128\nnum_heads = 8\ndff = 256\nmax_seq_len = 2560 #X_train.shape[1]\npe_input = 2560\nrate = 0.3\nnum_features = 1\n\n###### Defining Layers\nInput_layer = tf.keras.layers.Input(shape=(max_seq_len,num_features))\n\n##### Convolutional Filters\n\n### Layer-1\nconv1 = tf.keras.layers.Conv1D(32,15,padding='same',activation='relu')\nconv11 = tf.keras.layers.Conv1D(32,15,padding='same',activation='relu')\nconv12 = tf.keras.layers.Conv1D(32,15,padding='same',activation='relu')\nconv13 = tf.keras.layers.Conv1D(32,15,padding='same',activation='relu')\n\n### Layer-2\nconv2 = tf.keras.layers.Conv1D(64,15,padding='same',activation='relu')\nconv21 = tf.keras.layers.Conv1D(64,15,padding='same',activation='relu')\nconv22 = tf.keras.layers.Conv1D(64,15,padding='same',activation='relu')\nconv23 = tf.keras.layers.Conv1D(64,15,padding='same',activation='relu')\n\n### Layer-3\nconv3 = tf.keras.layers.Conv1D(128,15,padding='same',activation='relu')\nconv31 = tf.keras.layers.Conv1D(128,15,padding='same',activation='relu')\nconv32 = tf.keras.layers.Conv1D(128,15,padding='same',activation='relu')\nconv33 = tf.keras.layers.Conv1D(128,15,padding='same',activation='relu')\n\n#### Channel Attention Module\n#cam_module = CAM_Module(128,1)\n\n##### Transfromer Layer\n#transformer = Transformer(num_layers,d_model,num_heads,dff,pe_input,rate)\n\n##### Output Layer\ngap_layer = tf.keras.layers.GlobalAveragePooling1D()\n\n###### Defining Architecture\n##### Input Layer\nInputs = Input_layer\n\n##### Network\n#### Layer-1\nconv1_up = conv1(Inputs)\nconv_11 = conv11(conv1_up) \nconv_12 = conv12(conv_11)\nconv_13 = conv13(conv_12)\nconv_13 = tf.keras.layers.Add()([conv_13,conv_11])\n\n#### Layer-2\nconv2_up = conv2(conv_13)\nconv_21 = conv21(conv2_up)\nconv_22 = conv22(conv_21)\nconv_23 = conv23(conv_22)\nconv_23 = tf.keras.layers.Add()([conv_23,conv_21])\n\n#### Layer-3\nconv3_up = conv3(conv_23)\nconv_31 = conv31(conv3_up)\nconv_32 = conv32(conv_31)\nconv_33 = conv33(conv_32)\nconv_33 = tf.keras.layers.Add()([conv_33,conv_31])\n\n##### Transformer\n#embeddings =  transformer(inp=conv_33,enc_padding_mask=None)\n\n##### CAM Module\n#cam_op = cam_module(conv_33)\n#cam_op = tf.keras.layers.Add()([cam_op,embeddings])\n\n##### Output Layers\n#### Initial Layers\ngap_op = gap_layer(conv_33)\ndense1 = tf.keras.layers.Dense(256,activation='relu')(gap_op)\ndropout1 = tf.keras.layers.Dropout(0.3)(dense1)\ndense2 = tf.keras.layers.Dense(256,activation='relu')(dropout1)\ndense3 = tf.keras.layers.Dense(3,activation='softmax')(dense2)\n\n##### Compiling Architecture            \nmodel = tf.keras.models.Model(inputs=Inputs,outputs=dense3)\nmodel.load_weights('../input/mhm-stress-wesad-models/MHM_Stress_WESAD.h5')\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n\nmodel.summary()      \ntf.keras.utils.plot_model(model)\n\n###### Model Training \n\n##### Model Checkpointing\nfilepath = './MHM_Stress_WESAD.h5'\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath,monitor='val_accuracy',save_best_only=True,mode='max',save_weights_only=True)\n\n##### Softmax Training \n#history = model.fit(X_train,y_train,epochs=100,batch_size=32,\n#                validation_data=(X_dev,y_dev),validation_batch_size=32,\n#               callbacks=checkpoint)\n\n###### Plotting Metrics  \n##### Accuracy and Loss Plots \n\n#### Accuracy\n#plt.plot(history.history['accuracy'])\n#plt.plot(history.history['val_accuracy'])\n#plt.title('Model Accuracy')\n#plt.ylabel('Accuracy')\n#plt.xlabel('Epoch')  \n#plt.legend(['Train', 'Testing'], loc='best')\n#plt.grid(b='True',which='both')\n#plt.show()\n\n### Loss     \n#plt.plot(history.history['loss'])  \n#plt.plot(history.history['val_loss'])\n#plt.title('Model Loss')  \n#plt.ylabel('Loss')         \n#plt.xlabel('epoch')\n#plt.legend(['Train', 'Testing'], loc='best')\n#plt.grid(b='True',which='both')\n#plt.show()      ","metadata":{"execution":{"iopub.status.busy":"2022-02-26T19:44:09.895874Z","iopub.execute_input":"2022-02-26T19:44:09.896136Z","iopub.status.idle":"2022-02-26T19:44:13.845201Z","shell.execute_reply.started":"2022-02-26T19:44:09.896107Z","shell.execute_reply":"2022-02-26T19:44:13.844105Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"###### Function to Plot Confusion Matrix\nplt.rcParams[\"figure.figsize\"] = [6,6]\nimport itertools\ndef plot_confusion_matrix(cm,classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n    \n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n    \n###### Confusion Matrix Computation\ny_preds = model.predict(X_dev)\ncm = confusion_matrix(y_dev,np.argmax(y_preds,axis=1))\nprint('//////////////////////////////////')\nprint(cm)\nprint('//////////////////////////////////')\n\n###### Plotting Confusion Matix\ncm_plot_labels = ['Normal','Arrhythmia']\nplot_confusion_matrix(cm=cm,classes=cm_plot_labels,normalize=False,title='Confusion Matrix')\n#plot_confusion_matrix(cm=cm,classes=cm_plot_labels,normalize=True,title='Confusion Matrix')","metadata":{"execution":{"iopub.status.busy":"2022-02-25T22:06:53.621336Z","iopub.execute_input":"2022-02-25T22:06:53.621588Z","iopub.status.idle":"2022-02-25T22:06:55.190725Z","shell.execute_reply.started":"2022-02-25T22:06:53.621559Z","shell.execute_reply":"2022-02-25T22:06:55.190019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####### Model Testing\n\n###### Testing Model - ArcFace Style                \n    \ndef normalisation_layer(x):   \n    return(tf.math.l2_normalize(x, axis=1, epsilon=1e-12))\n\npredictive_model = tf.keras.models.Model(inputs=model.input,outputs=model.layers[-2].output)\npredictive_model.compile(tf.keras.optimizers.Adam(lr=1e-4),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n\n#y_in = tf.keras.layers.Input((11,))\n\nInput_Layer_rdi = tf.keras.layers.Input((max_seq_len,num_features))\n#Input_Layer_rai = tf.keras.layers.Input((T,H,W,C_rai))\nop_1 = predictive_model(Input_Layer_rdi)\n\n##Input_Layer_Flipped = tf.keras.layers.Input((224,224,3))\n##op_2 = predictive_model([Input_Layer_Flipped,y_in]) \n##final_op = tf.keras.layers.Concatenate(axis=1)(op_1)\n\nfinal_norm_op = tf.keras.layers.Lambda(normalisation_layer)(op_1)\n\ntesting_model = tf.keras.models.Model(inputs=Input_Layer_rdi,outputs=final_norm_op)\ntesting_model.compile(tf.keras.optimizers.Adam(lr=1e-4),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n\n##### Nearest Neighbor Classification\nfrom sklearn.neighbors import KNeighborsClassifier\nTest_Embeddings = testing_model.predict(X_dev)\nTrain_Embeddings = testing_model.predict(X_train)\n\ncol_mean = np.nanmean(Test_Embeddings, axis=0)\ninds = np.where(np.isnan(Test_Embeddings))\n#print(inds)\nTest_Embeddings[inds] = np.take(col_mean, inds[1])\n\ncol_mean = np.nanmean(Train_Embeddings, axis=0)\ninds = np.where(np.isnan(Train_Embeddings))\n#print(inds)\nTrain_Embeddings[inds] = np.take(col_mean, inds[1])\n\n###### t-SNE Plotting\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\n\n#### Computing and Saving Output \n#np.savez_compressed('./Embeddings/RDCML_Softmax_Ablation.npz',Test_Embeddings)\n\n#### t-SNE Plots\n### t-SNE Embeddings\ntsne_X_dev = TSNE(n_components=2,perplexity=30,learning_rate=10,n_iter=2000,n_iter_without_progress=50).fit_transform(Test_Embeddings) # t-SNE Plots \n\n### Plotting\nplt.rcParams[\"figure.figsize\"] = [12,8]\nfor idx,color_index in zip(list(np.arange(3)),sns.color_palette()):\n    plt.scatter(tsne_X_dev[y_dev == idx, 0],tsne_X_dev[y_dev == idx, 1],s=40,color=color_index,edgecolors='k',marker='h')\nplt.legend(['Baseline','Stressed','Amusement'],loc='best')\nplt.grid(b='True',which='both')\nplt.savefig('./MHM_Stress_WESAD_Softmax_Ablation.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T19:55:01.096642Z","iopub.execute_input":"2022-02-26T19:55:01.097192Z","iopub.status.idle":"2022-02-26T19:55:27.270237Z","shell.execute_reply.started":"2022-02-26T19:55:01.097157Z","shell.execute_reply":"2022-02-26T19:55:27.269712Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"x = # Dimensions: (2560,1) Numpy Array \nx = (x - np.mean(x))/np.std(x)\nx = np.reshape(x,(1,2560,1))\n\nmodel.predict(x)","metadata":{},"execution_count":null,"outputs":[]}]}